Preparation:

Put the login.pem file in ~/data (this location is currently hardcoded)

To create the "LAN" experiment with $S servers and $C clients:

S=...
C=...

exp="S${S}L$C"
mkdir /tmp/$exp
./bin/mknet S=$S L=$C EXP=$exp [other options, see below]

To create the "WAN" experiment with $S servers, $L clients per LAN and
$R router levels:

S=...
L=...
R=...

exp="S${S}R${R}L$L"
mkdir /tmp/$exp
./bin/mknet S=$S L=$L R=$R EXP=$exp [other options, see below]

other options:
    PWD=~/data/login.pwd     file containing password for login.pem
    K=~/.ssh/id_rsa.pub      add another allowed ssh key to the testbed
                             (the one from login.pem and the one in the
                             "objects" directory are added automatically)
    Klibrecas=~/data/id_rsa.pub
                             Add key for non-default user (here "librecas")

If no other keys are specified with "K=", the default key from login.pem
as well as the private key in the "objects" directory can be used to log
in to the testbed: the latter key is also used by the nodes to talk to
each other.

xvfb-run java -Djdk.gtk.version=2 -jar ~/jfed_cli/experimenter-cli2.jar \
    -a /tmp/$exp/action.yaml

This takes about 10 minutes, then it stops without saying anything;
to check progress:

tail /tmp/$exp/debug.txt

To prepare the testbed for the experiment using $SIZES data sizes
(a comma-separate list, in megabytes)

SIZES=...

./bin/setup-experiment $SIZES $exp

This currently copies all the information to the testbed but does not set
things up and run the experiment.  Log in to the "director":

./bin/ssh-experiment $exp director0

On the director itself, start by setting up all the other nodes:

/tmp/experiment/setup-all

And then run the experiment:

/tmp/experiment/run-experiment

Alternatively to leave the experiment running until the testbed expires:

while true; do /tmp/experiment/run-experiment; done

To log in to any other node:

./bin/ssh-experiment $exp NODE_NAME

To run a command using ssh:

./bin/ssh-experiment $exp NODE_NAME PROGRAM [ARGUMENTS]

If the scripts have been edited locally, they can be updated on the testbed
by re-running setup-experiment locally, then asking director0 to copy
them to all other nodes:

./bin/setup-experiment SIZES $exp
./bin/ssh-experiment $exp director0 /tmp/experiment/copy-experiment

To copy data to/from a node in the experiment, there are two scripts,
rsync-to-experiment and rsync-from-experiment, called as:

./bin/rsync-to-experiment EXP_NAME NODE RSYNC_OPTIONS LOCAL_SOURCE [LOCAL_SOURCE]... REMOTE_DEST
./bin/rsync-from-experiment EXP_NAME NODE RSYNC_OPTIONS REMOTE_SOURCE [REMOTE_SOURCE]... LOCAL_DEST

for example after building new binaries in /tmp/binaries on director0 one
could copy them back to the objects directory with:

./bin/rsync-from-experiment $exp director0 -avHP /tmp/binaries/ objects/

or for more complicated rsync options:

./bin/rsync-from-experiment $exp director0 '-avHP --delete' /tmp/binaries/ objects/

==============================================

To extract the data produced by the experiments to a set of files in a
directory, if the data is in $SRC_DIR and the results will go into
$DST_DIR:

./bin/extract-data "$SRC_DIR" "$DST_DIR" '*'

Or to extract only some files matching PATTERNS:

./bin/extract-data "$SRC_DIR" "$DST_DIR" PATTERNS

The extracted files in $DST_DIR will have names like

NODE.EXPERIMENT.SCHEDULING.SIZE.TOPOLOGY.TIMESTAMP

for example:

server0.multicast.immediate.128.S1R2L2.20211219135844

These are lwmon binary files; to display the contants (install lwmon and) type:

lwmon -P- -R "$DST_DIR"/server0.multicast.immediate.128.S1R2L2.20211219135844

See lwmon(1) for other options

Alternatively, the data can be imported into a SQLite database with:

./bin/import-into-sqlite database.sqlite "$DST_DIR"/*

The sql directory contains some simple SELECT statements to extract some
information. More useful reports are planned.


\documentclass[a4paper,12pt,twocolumn]{article}

\usepackage{ifpdf}

\hbadness=3000
\vbadness=4000

\title{Comparing performance of IPv6 multicast and unicast for software updates}
\author{Claudio Calvelli}
\date{Draft 0.5 \today}

\setlength{\unitlength}{0.01\linewidth}
\def\topfaction{0.6}
\def\bottomfraction{0.6}

\newcommand{\TODO}[1]{\par\noindent%
\hspace*{\fill}%
\framebox{\parbox{0.9\linewidth}{{\bf TODO: }#1}}%
\hspace*{\fill}%
}

% everybody say to just include the hyperref package - it's big, ugly and
% breaks the next command.  This on the other hand works just fine
\ifpdf
\newcommand{\longurl}[2]{%
\pdfstartlink %
attr {/Border [0 0 0]} %
user {/Subtype /Link /A << /S /URI /URI (#1) >>}%
{\footnotesize\tt #2}\pdfendlink}
\newcommand{\url}[1]{\longurl{#1}{#1}}
\else
\newcommand{\url}[1]{{\footnotesize\tt #1}}
\newcommand{\longurl}[2]{{\footnotesize\tt #1}}
\fi

\newcommand{\pref}[1]{%
\ref{#1}%
\ifnum\thepage=0\pageref{#1}\else\ on page~\pageref{#1}\fi%
}

\begin{document}
\maketitle

\begin{abstract}
The librecast project states that ``Multicast is, by definition, the most
efficient way for multiple nodes to communicate''.  This experiment is
designed to provide evidence of this efficiency by comparing multicast
and unicast methods of sending the same data to a large number of nodes,
as would for example happen when a software update is released.

\TODO{Report the actual results after we run the experiment}
\end{abstract}

\section{Introduction}
The first paragraph of RFC 3170~\cite{rfc:3170} states:

\begin{quotation}
\noindent
IP Multicast will play a prominent role on the Internet in the coming
years.  It is a requirement, not an option, if the Internet is going
to scale.  Multicast allows application developers to add more
functionality without significantly impacting the network.
\end{quotation}

There is a need for some experimental data to back these statements.
We concentrate of measuring the impact of {\it software
updates\/} on the network, because the proliferation of connected
devices will make software updates a very important target for
efficient use of the network, and because software updates are
easy to simulate realistically by measuring the impact of copying
a large file to a large number of nodes.

To provide evidence for the above statements, we compare the
following methods of providing updates:

\begin{itemize}
\item Traditional unicast using a TCP-based service: a
server listens to TCP requests to send a copy of the software
update, and each client requests
the update from the server: this is the mechanism used by the vast
majority of current services.
\item Full multicast: a number of servers provide the software
update using multicast, and clients will obtain the updates by
joining a multicast group and waiting for the data to arrive.
\item Unicast using a UDP-based service: this is similar to the
TCP case, but uses datagrams instead of virtual circuits: this
mechanism is introduced because multicast is by necessity based
on datagrams: there is no feedback from receiver to sender, and
we want to help determine which differences may be caused by
unicast vs.\ multicast, and which ones by virtual circuits vs\.
datagrams.
\end{itemize}

Additionally, we also measure the effect of a simple ``scp''
of the file, to confirm that the setup works with standard,
well-tested tools.

Apart from the ``scp'' runs, do not use encryption in this experiment,
all the three methods send the data unencrypted and verify that it
has arrived correctly using a secure hash: this corresponds to the way
some software updates are distributed, with an HTTP mirror providing
the data and a secure hash provided by some more secure mechanism; we
do not expect the results to be different when excription is used for
all transmissions, as used in many other cases, but we might consider
a future experiment to test this.

Independently of the method selected, there are two ``client''
scheduling strategies:

\begin{itemize}
\item All clients request updates at approximately the same time
(the ``immediate'' strategy).
\item Clients wait a random time before requesting the update
(the ``random'' strategy).
\end{itemize}

We run the simulated software updates in a variety of network
configurations and with a variety of file sizes to simulate the
impact of different types of updates; in each case we measure network
use, server load, client load and speed of update for each combination
of update mechanism and scheduling strategy.

The rest of this report is structured as follows:

Section~\ref{LAN:experiment} describes the simplest possible network
topology in which we can get useful measurements, and provides details
on how we run the experiment.

Sections~\ref{TWOLAN:experiment} and~\ref{GEN:experiment} describe
two more network topologies, incresing the complexity and studying
how different features affect the results.

Section~\ref{results} analyses the result of the experiment and compares
the efficiency of unicast, multicast, and the transitional technology.
There are also notes about testbed issues we identified, because anybody
wishing to repeat the experiment will need to make sure they select
an experiment testbed which is properly configured for IPv6 multicast.

Section~\ref{future} explores the possibility of further experiments,
to make the simulation more realistic and more complete.

Appendix~\ref{programs} provides some more details about the various
programs which ran as part of the experiment, and where to find the
full sources of all these programs.

Appendix~\ref{configuration} provides some important information to
anybody who wants to repeat this experiment, and how to check if
an experiment setup is configured as required.

\section{``LAN'' experiment}
\label{LAN:experiment}

A number of clients (denoted by ${\cal C}$) request software updates
from a single server; the server and all clients share a LAN
so that updates have the shortest possible netowrk path.  This
experiment will allow us to compare multicast and unicast in the
simplest possible setting, and one which is possible on any existing
local network in which IPv6 is enabled, and could represent for example
distributing updates within an organisation.

A second experimental parameters indicates the size of the software updates
as the number ${\cal N}$ of bytes contained in it.  In the real world,
clients may be more or less up-to-date so that each one may request a
subset of all updates available; for this experiment we assume that
all clients have all previous updates and are just requesting the latest
one; a future experiment may consider some more complex ``real life''
scenarios.

Figure~\pref{s1:c8}
\begin{figure}[bp]
\begin{center}
\begin{picture}(90,29)
\put(45,22){\makebox(0,0){\rm\bf S}}
\put(45,16){\line(0,1){3}}
\put(10,16){\line(1,0){70}}
\multiput(10,13)(10,0){8}{\line(0,1){3}}
\multiput(10,10)(10,0){8}{\makebox(0,0){\rm\bf C}}
\end{picture}
\end{center}
\hspace*{\fill}%
\mbox{{\bf S} = server;}%
\hspace*{\fill}%
\mbox{{\bf C} = client}%
\hspace*{\fill}
\caption{Network with8 clients on a single LAN}
\label{s1:c8}
\end{figure}
shows the network topology with ${\cal C} = 8$, i.e.\ there is a
server sending data to 8 clients on a single LAN.

\subsection{Experiment procedure}
For a specified network topology (i.e.\ value for ${\cal C}$), and a list
of update sizes (several distinct values for ${\cal N}$), we implement
that network on an experiment testbed, then run a series of tests on
it using all possible combinations of update size, update method and
scheduling strategy.  For organisational reasons, the testbed actually
has 2 servers, the extra server does not take part in the update but
directs the operations and collects results (we call this extra server
the ``director'').

Each test starts with the director generating a file of the specified size
filled with random data; this is copied to the server (a future experiment
will use multiple servers, so generating the file on the director and
copying it to all servers will make sure all send the same data, and
in preparation for that we have this extra file copy instead of generating
a random file directly on the server).

After generating and copying the file the director waits 60 seconds to
make sure that the 1-minute load average of each node in the system is
down to its baseline value; when we ran experiments without this wait,
we had each run affecting the measurements of the next one, so it did
not produce useful results.

After the 60 seconds wait, the director asks the server node to start:
this means starting two daemons, a resource monitoring tool and the
update provider appropriate for the selected update method.  These
update providers are described below.

After the server has started, the director asks all client nodes to
start as well: each client will first wait a short time depending on
the scheduling strategy: a fixed 4 seconds for ``immediate'' or a
random duration between 4 and 36 seconds for ``random''; the minimum
wait of 4 seconds is to make sure the rest of the system is fully
ready to run. After this delay, each client starts a resource monitoring
daemon identical to the one running on the server, and a client
program to obtain the update.

When a client has successfully obtained the update, the monitoring
daemon will record the time it has taken, finish another round of
resource measurements, and sends all the data back to the director.

The director waits for all clients to have sent the data, then asks the
server to stop, which will also trigger a copy of the server's resource
measurements back to the director: all the measurements from all nodes
are collected into a single ``tar'' archive and saved for later analysis.

The resource monitoring daemon records the following data every second:

\begin{itemize}
\item 1-minute load average as provided by the system
\item user and system CPU time used by the whole systemin the last second
\item memory and swap use
\item bytes sent and received on the network interface used to
transfer the update data
\end{itemize}

Additionally, at the end of the experiment it also records the following
data about the update program itself (update provider for server, or
the program obtaining the update for clients):

\begin{itemize}
\item Time elapsed between start and termination of the program, in milliseconds
\item CPU time used by the program itself, in milliseconds
\item CPU time used by the operating system to run the program, in milliseconds
(this includes, for example, time used to obtain data from disk)
\item The termination status: whether the program reported an error
\end{itemize}

Since the experiment procedure is automated by running a single program
on the director, where possible we ran it many times on the same
testbed, to have more experimental data without the extra overhead
of setting up a new testbed.

We ran three versions of this experiment, with 20 and 64 clients.  We
have been unable to run a larger experiment as there were never sufficient
resources available on the testbed, so we have been unable to show scale
issues properly.

\subsection{Update methods}
The ``multicast'' method uses the ``IoT updater'' demonstration
program~\cite{iotupd:paper} to copy a file from server to clients: on the
server side ``iotupd'' calculates the file's checksum, then runs a loop in
which it sends the whole file and the checksum to a specified multicast
group, then repeats the sending until asked to stop at the end of the
experimend.  Each client runs ``iotupc'' which waits for the data to
arrive on the specified group and saves it to a local file, stopping when
the file checksum matches.  There is no feedback from client to server,
and no mechanism for a client to require retransmission of missing data;
however the client can just wait for the server to send it again. More
details on the IoT updater can be found in appendix~\ref{iotupd} or in
the source code~\cite{iotupd:sources}.

The unicast ``scp'' method just uses the ``scp'' program (part of
openssh) on each client to connect to the server and ask for a copy of
the file: this allows us to show that the experiment setup is working
with some well-known software; however the presence of encryption
means that the results are not directly comparable with other experiments;
a future experiment in which all methods use encryption will of course
benefit from inclusion of this method.

The unicast ``tcp'' experiment is similar in concept to the ``scp'' one,
but implemented with code as similar as possible to the multicast case
to make comparisons more meaningful.  On the server side, the ``iotup''
program (in TCP server mode) calculates the file checksum then waits for
connections; it replies to each connection with the file checksum and
the full file data, sent as a single TCP stream.  On the client side,
the ``iotup'' program (in TCP client mode) connects to server, saves the
file data, calculates the checksum and compares it with the one sent by
the server; if the checksum match, the program exits with success, otherwise
it retries the whole download. Because TCP already does its own verification,
it is unlikely that the client will ever have to retry in this experiment
when everything runs in the same building; however in a future larger and
more distributed experiment we can expect to encounter network issues
which will require retries from the client. The ``iotup'' program is
described more fully in appendix~\ref{unisync} and its sources are available
in~\cite{unisync:sources}.

The unicast ``udp'' method is very similar to the ``tcp'' method,
but uses UDP rather than TCP and that implies that retransmissions
and duplicate detection need to be handled at the application level.
On the server side, the ``iotup'' program (in UDP server mode) calculates
the file checksum, then waits for requests coming in via UDP; these
request specify a range of bytes to send, and the server replies with a
sequence of UDP packets, each of which contain the same information as
the packets sent using the ``multicast'' method.  Each client starts by
requesting the whole file (specifying both start and end offsets as 0,
which the server interprets as ``from 0 to end of file'') and waiting
for data: if there is no reply within a pre-determined time, it will
retry the request.  Once at least one packet arrives to the client,
it will know the total data size and the file checksum, and will have
part of the data.  The client will wait until all the expected data has
arrived, or a timeout occurs in which no new packets have arrived for a
pre-defined time.  The client will then decide whether any part of the
file needs retransmitting and continue until it has received all the
data it expects, and the file checksum matches.  The ``iotup'' program
is described more fully in appendix~\ref{unisync} and its sources are
available in~\cite{unisync:sources}.

\section{``Two LANs'' experiment}
\label{TWOLAN:experiment}

Similar to the previous experiment, but we investigate the effect of a
multicast router in the network: there are two LANs connected together
by a single router; the server is on the first LAN, and all the clients
are on the second LAN.  Like the previous experiments, the parameters are
the number of clients ${\cal C}$, and the update size in bytes ${\cal N}$.

Figure~\pref{s1:r1:c8}
\begin{figure}[bp]
\begin{center}
\begin{picture}(90,38)
\put(45,31){\makebox(0,0){\rm\bf S}}
\put(45,25){\line(0,1){3}}
\put(45,22){\makebox(0,0){\rm\bf R}}
\put(45,16){\line(0,1){3}}
\put(10,16){\line(1,0){70}}
\multiput(10,13)(10,0){8}{\line(0,1){3}}
\multiput(10,10)(10,0){8}{\makebox(0,0){\rm\bf C}}
\end{picture}
\end{center}
\hspace*{\fill}%
\mbox{{\bf S} = server;}%
\hspace*{\fill}%
\mbox{{\bf R} = router;}%
\hspace*{\fill}%
\mbox{{\bf C} = client}%
\hspace*{\fill}
\caption{Two LANs network with 8 clients}
\label{s1:r1:c8}
\end{figure}
shows the network topology with ${\cal C} = 8$, i.e.\ the same setting
as the previous example (figure~\pref{s1:c8}) but with the clients
separated from the server by a single router.

The experimental procedure is very similar to the previous experiment,
we only describe the differences between them here.

After copying the update data to the server and waiting 60 seconds, the
director will ask the router to start its own resource monitoring, and,
for the multicast experiment, to start a multicast routing daemon. We
used ``pim6sd''~\cite{pim6sd:sources} for this experiment, although we
plan to develop our own multicast routing daemon and future experiments
will use it.

The server wait 2 seconds before starting, to give the router time to be
fully set up.

After that, the experiment proceeds identically with the director starting
all clients and waiting for results.

We only ran a 20 clients version of this experiment, when there happened
to be free resources for this but not for anything larger.

\section{``Generic'' experiment}
\label{GEN:experiment}

An extension of the previous (``Two LANs'') experiment includes a longer
network path between clients and server; for simplicity, and to generate
the networks automatically, we specify a number of clients per LAN
(denoted by ${\cal L}$) and the length of the network path indicated by
the number of routers in the path, ${\cal R}$. The total number of clients
will be ${\cal C} = {\cal L} * 2^{{\cal R} - 1}$, and the routers form a
tree structure.

A couple of exampels will make this clearer: figure~\pref{s1:r3:l2}
\begin{figure}[bp]
\begin{center}
\begin{picture}(90,62)
\put(45,55){\makebox(0,0){\rm\bf S}}
\put(45,49){\line(0,1){3}}
\put(45,46){\makebox(0,0){\rm\bf R}}
\put(45,40){\line(0,1){3}}
\put(25,40){\line(1,0){40}}
\multiput(25,37)(40,0){2}{\line(0,1){3}}
\multiput(25,34)(40,0){2}{\makebox(0,0){\rm\bf R}}
\multiput(25,28)(40,0){2}{\line(0,1){3}}
\multiput(15,28)(40,0){2}{\line(1,0){20}}
\multiput(15,25)(20,0){4}{\line(0,1){3}}
\multiput(15,22)(20,0){4}{\makebox(0,0){\rm\bf R}}
\multiput(15,16)(20,0){4}{\line(0,1){3}}
\multiput(10,16)(20,0){4}{\line(1,0){10}}
\multiput(10,13)(10,0){8}{\line(0,1){3}}
\multiput(10,10)(10,0){8}{\makebox(0,0){\rm\bf C}}
\end{picture}
\end{center}
\hspace*{\fill}%
\mbox{{\bf S} = server;}%
\hspace*{\fill}%
\mbox{{\bf R} = router;}%
\hspace*{\fill}%
\mbox{{\bf C} = client}%
\hspace*{\fill}
\caption{Network with 8 clients, 2 clients per LAN}
\label{s1:r3:l2}
\end{figure}
shows the network topology with ${\cal R} = 3$ and ${\cal L} = 2$,
so that the 8 clients are organised in 4 separate LANs, with
7 routers forming a tree structure with the server connected to
the root of the tree. For comparison, figure~\pref{s1:r2:l4}
\begin{figure}[bp]
\begin{center}
\begin{picture}(90,50)
\put(45,43){\makebox(0,0){\rm\bf S}}
\put(45,37){\line(0,1){3}}
\put(45,34){\makebox(0,0){\rm\bf R}}
\put(45,28){\line(0,1){3}}
\put(25,28){\line(1,0){40}}
\multiput(25,25)(40,0){2}{\line(0,1){3}}
\multiput(25,22)(40,0){2}{\makebox(0,0){\rm\bf R}}
\multiput(25,16)(40,0){2}{\line(0,1){3}}
\multiput(10,16)(40,0){2}{\line(1,0){30}}
\multiput(10,13)(10,0){8}{\line(0,1){3}}
\multiput(10,10)(10,0){8}{\makebox(0,0){\rm\bf C}}
\end{picture}
\end{center}
\hspace*{\fill}%
\mbox{{\bf S} = server;}%
\hspace*{\fill}%
\mbox{{\bf R} = router;}%
\hspace*{\fill}%
\mbox{{\bf C} = client}%
\hspace*{\fill}
\caption{Network with 8 clients, 4 client per LAN}
\label{s1:r2:l4}
\end{figure}
shows the same number of clients arranged on 2 separate LANs
(${\cal L} = 4$) so that there are only 2 routers between each
client and the server (${\cal R} = 2$).

This is still a simplified view of a real system, but allows to
extend the previous experiments to different circumstances.  A
future experiment might consider different networks.

The experiment proceeds almost identically to the ``Two LANs''
experiment described above: there are more routers, but they are
all set up in the same way as the single router on that experiment.

We ran experiments corresponding to both examples shown in the figures,
using 20 clients rather than 8.

\section{Experiment results}
\label{results}

\TODO{Show tables, graphs, link to result data--and draw conclusions}

\section{Future work}
\label{future}

Due to time limitations we have only measured network performance for
a small set of regular network topologies, corresponding to the example
networks shown in sections~\ref{LAN:experiment} to~\ref{GEN:experiment},
using more clients than shown in the figures; of course the real world
is made up of rather more irregular topologies and it it would be
interesting to investigate more variations in this area in a future set
of experiments.

We also limited the experiments to 64 clients, as we have been unable
to allocate larger networks: the testbed never had enough free
resources.  To properly test how the various method scale, we would
need some experiment setup where we can easily allocate 500 or more
nodes.

Alternatively, we would like to run the experiment distributed across
several sites to have a much larger number of total nodes, and also a
more representative network structure.  However the unicast experiments
are likely to require massive amount of network bandwidth, and the
multicast experiments require proper multicast configuration at all
sites and multicast routing between then, so these factors will limit
the choice of sites.

We also simplified the software update by assuming that all clients
request exactly the same file, rather than a more complex situation
in which every client requests a different subset of all available
updates, due to its own unique update history; while we expect that
multicast will scale really well to this situation, we haven't
ran an experiment to support this.

All the experiments we ran included a single server.  The main point
of this experiment was to show that a single server is sufficient to
provide updates for a large number of clients using multicast, while
unicast will require multiple servers in this case.  However, there
are reasons other than server and network load why one would want
multiple servers, for example reliability: if the single, extremely
efficient, server has a fault, the updates stop; ideally, these
multiple servers will be reachable by completely different network
paths as well.  We think that multicast will help with that too,
for example multiple servers can each send data at a fraction of the
bandwidth, and when all works clients will get the advantage of the
combined output from all servers, with a network or server failure
would automatically result in a corresponding reduction of speed, and
the subsequent recovery or replacement of the faulty parts would
automatically result in the system returning to full speed.  This
claim, of course, needs a separate experiment to justify.

Another type of network activity which can benefit from multicast is
live streaming, where the server will only need to send the stream once;
this case is similar to software updates and probably does not need a
separate experiment; however if several choices of bandwidth and quality
are required the situation is different.  In the unicast case it's obvious
how the sender can provide different quality streams to different clients,
for multicast the simplest answer is to provide several streams with
different quality, with the client subscribing to the one which best
match its requirements: this would save network and server resources
but there may be better way of achieving this result, for example using
layered codecs to send only one copy of the lowest quality stream, then
a second stream with the difference between that and the next highest
quality. We don't know at present if these codecs would involve more
server resources than the re-encoding required to provide multiple
stream with different quality, but in any case we would find it useful
to run another experiment to measure these costs and compare them with
the expected savings in terms of network usage.

For this experiment we transmitted all data unencrypted between the nodes
and used a secure hash to determine whether it was received correctly.
This corresponds to a traditional situation in which HTTP mirrors provide
the data, and a checksum is provided over a more secure mechanism for
verification.  More recently, most systems are moving to HTTPS with the
added overhead of encryption on every communication: we expect that the
benefits of multicast shown in this experiment will continue to apply,
but we have not tested this, and might consider a future experiment in
which we extend the multicast update method to add encryption of all
communication, comparing this with the normal stream encryption used
for example with HTTPS.

\appendix
\section{Programs}
\label{programs}

To run each experiment we had to implement a network topology on an
experiment testbed, set up each node in the testbed, run the experiment
itself and collect the results; additionally, we had to analyse the
results of groups of experiments together.  This appendix describes
the programs used for all various tasks, and includes references to
where the full source code can be found for the programs we developed.

\subsection{Preparing a testbed and running an experiment}

{\em The programs described here and other useful tools are in the experiment
setup repository~\cite{exp:scripts} under the {\tt bin} directory for
the programs to run on the local system and the {\tt objects} directory
for the programs to run on the testbed.}

Given the number of servers, clients and routers (if appropriate to the
experiment) we developed a simple program to generate action files
for ``jfed''~\cite{jfed} so that the process could be automated; a single program
``mknet'' provided action files for all the experiment topologies
described in this report by providing appropriate options; for the
networks shown as examples in the figures we just ran:

\begin{small}
\begin{verbatim}
local$ mknet L=8
local$ mknet R=1 L=8
local$ mknet R=3 L=2
local$ mknet R=2 L=4
\end{verbatim}
\end{small}

As can be seen, omitting ``R'' results in a single LAN network in which
the number of clients is specified by ``L'' for consistency with the
other networks (where it indicates the number of clients on each client
LAN).

By default, the program generates an experiment name indicating the
parameters provided: for the four examples above this would be: ``S1L8'',
``S1R1L8'', ``S1R3L2'' and ``S1R2L4''; the data generated will be stored
in a directory inside {\tt/var/tmp} named after the experiment (the name
of the experiment starts with ``S1'' to indicate the number of servers,
in preparation for a future multi-server experiment, and the directory
can be changed with other command-line options).

One of the files generated, {\tt action.yaml}, is suitable for using
as argument to the {\tt-a} (action file) option to the ``jfed-cli''
tool and will provision the testbed; the program also generates {\tt
action.rspec} which is suitable for using with the ``jfed-gui'' tool.
We do not describe these tools here as they are provided by fed4fire,
but see~\cite{jfed}.

Once the testbed is up and running, we need to copy some things to it,
for example the actual programs which will run on it and information about
the experiment to run.  The list of data sizes is also specified at
this point, for example to run with 32, 64 and 512 megabytes on the
first single LAN experiment defined above (``S1L8'')

\begin{small}
\begin{verbatim}
local$ setup-experiment 32,64,512 S1L8
\end{verbatim}
\end{small}

This sets up the ``director'' node and copies the {\tt objects} directory
of the repository to it.  To complete the setup, one needs to connect to
it and then run a program there:

\begin{small}
\begin{verbatim}
local$ ssh-experiment S1L8 director0
director0$ /tmp/experiment/setup-all
\end{verbatim}
\end{small}

The testbed is now ready to run the experiment by running a program on
director0:

\begin{small}
\begin{verbatim}
local$ ssh-experiment S1L8 director0
director0$ cd /tmp/experiment
director0$ ./run-experiment
\end{verbatim}
\end{small}

If required, the ``{\tt run-experiment}'' program can run many times
to obtain more data without additional setup overhead; no need to
repeat any of the previous steps.

Internally, the ``{\tt run-experiment}'' program calls other programs
running on the director, but also on servers, routers and clients
as necessary to implement the procedure described in
sections~\ref{LAN:experiment} to~\ref{GEN:experiment}. These
have names like ``{\tt start-tcp-server}'' or
``{\tt start-multicast-router}'' to start what is required for
a particular experiment on a particular node (in this example,
start the TCP experiment on a server, and start the multicast
routing daemon on a router, respectively).  All these programs are
found in the repository cited.

One issue we found while developing programs to automate the experiment
is that network interface names may be different when booting different
testbeds; each node has two interfaces, a control interface used by
the testbed administration, as well as to log in to it from outside
the experiment, and a second interface connected as required by the
experiment's network topology and used to transfer the data files during
the experiment; for a router node, there are obviously more interfaces:
therefore we needed to determine what interface name was actually
assigned to what.  The fed4fire documentation mentions a tool to obtain
the necessary information on each node, however the tool did not work:
it required a version of Python which is no longer available, and all
it produced for us was a syntax error.  Instead of debugging that,
it was easier for us to have the ``setup-all'' script figure out what
interface is going to be used for what based on the MAC address listed
in the output from the jfed program, and configure them as required:
this may be different for each node.  It also sets up the monitoring so
that the interfaces are reported in a consistent way, as is important
when looking at network usage data for routers.

\subsection{Resource monitoring}
\label{lwmon}
{\em The program described here is in the lwmon
repository~\cite{lwmon:sources}.}

There are many monitoring tools for Unix system, however in our experience
they tend to use more resources than programs which do the actual work,
or else they are designed to sample information only once a minute,
which is not enough for this experiment.

Because of experience using other monitoring tools and not finding
one which we actually want to use on a live system, we have developed
our own over the years, which we call ``lwmon'', for Light-Weight
system MONitoring, which, as the name suggests, is very considerate
in its use of resources and can safely run very frequently without
impact on the system.  It can also report on its own resource usage,
so one can confirm that it is, indeed, light-weight.

Without going into complete details, each node sets up its own
configuration for lwmon, which then measures memory, swap, cpu and
network usage and system load every second, its own resource usage every
10 seconds.  The appropriate program (update provider for servers, routing
daemon for routers if requires by the experiment, and the program which
gets the updates for clients) also runs as a child process of lwmon,
so the latter can report on the resource used by this program.

A lwmon configuration for a client is shown in figure~\pref{lwmon:client}.
\begin{figure*}[bp]
\begin{verbatim}
hostname client2

load lavg 1
cpu cpu 1
memory memswap 1
network if1 1 enp6s0
self self 2

program exp 5 /tmp/experiment/start-multicast-client enp6s0
print /tmp/results/client2.multicast.random.64 overwrite binary
\end{verbatim}
\caption{lwmon client configuration}
\label{lwmon:client}
\end{figure*}
This means that load average, memory/swap usage and network usage are
sampled every second, lwmon's own resource usage every 2 seconds, will
run the appropriate program for a particular experiment (in this case,
update via multicast), and save the information into a file in a compact
binary format. The second column of the lines specifying what to measure
is the name used to report it.

The program running does not depend on the scheduling strategy selected,
as that is handled before: we do not want to measure the time it takes
to sleep for a random duration, only the time it takes to download the
update.  The file name for the results, on the other hand, contain the
scheduling strategy (in this case, random) and the update size (64
megabytes), as we need to keep things distinct.

Another thing to note is that the ``network'' line asks to monitor
the interface using its systemd name (enp6s0 in this example) because
that's how it will be able to find it in the system, but reports it
using the name ``if1'' as this is the interface name we have used
in the action file and rspec.

The configuration for a server is essentially identical, with ``client''
replaced by ``server'', and for a router it is very similar, as shown
in figure~\pref{lwmon:router}.
\begin{figure*}[bp]
\begin{verbatim}
hostname router0

load lavg 1
cpu cpu 1
memory memswap 1
network if1 1 enp4s0
network if2 1 enp6s0
self self 2

program exp 5 /tmp/experiment/start-multicast-router enp4s0
print /tmp/results/router0.multicast.random.64 overwrite binary
\end{verbatim}
\caption{lwmon router configuration}
\label{lwmon:router}
\end{figure*}
The network interface reported as ``if1'' has network traffic going
to or from clients, and ``if2'' has traffic going to or from servers.

Once the ``{\tt start-}\ldots'' program terminates, lwmon automatically
reports on its resource usage and the wall clock time it has taken to run,
then runs one more round of measurements and exits.  For clients, the
program normally terminates when it has obtained the update successfully;
for servers and routers the program terminates when the director signals
the end of the experiment.

The program which generates the lwmon configuration file and calls lwmon
will wait for it to terminate, then copies the file it produced back
to the director node. This allows the director to collect all the
data about the experiment in one place.

As mentioned, lwmon produces a file containing data in a packed binary
format. To just look at the data, the tool has an option to read that
binary file back in and produce a human-readable output:

\begin{small}
\begin{verbatim}
$ lwmon -P - \
  -R data/router0.multicast.random.64
\end{verbatim}
\end{small}

There is a separate tool which reads one or more data files and produces
SQL statements which can be used to import it into a database, for example:

\begin{small}
\begin{verbatim}
$ lwmon-to-sql [options] FILES | \
  sqlite3 database.sqlite
\end{verbatim}
\end{small}

As described below in~\ref{importing}, for this experiment we have developed
a tool which calls {\tt lwmon-to-sql} in the appropriate way to import
experiment results in a format suitable for further analysis.

\subsection{Multicast update method}
\label{iotupd}
\TODO{iotupd}

\subsection{Unicast update methods}
\label{unisync}
\TODO{unisync}

\subsection{Importing results into a database}
\label{importing}

{\em The programs described here are in the ``experiment scripts''
repository~\cite{exp:scripts}.}

The ``lwmon'' program (appendix~\ref{lwmon}) produces a lot of data, as it
measures several items every second, and of course each node in the
experiment produces its own set of measurements.  The end result is that
we have tens of millions of data items divided into thousands of ``tar''
archives, each one produced by a single experiment run; inside these
archives, files are named after the node which produced them (for example,
client1 or router0) and the actual experiment ran (for example, multicast
or tcp) but other information is only in the name of the archive itself,
so the first step is to extract all these files renaming them so that
the names contain all the necessary information (this situation is because
when we started running the experiments, only the ``director'' node
had all the information, but the file names were generated by the nodes
creating the files: in a future experiment we are planning to change this).

These tar archives have names like:

\begin{small}
\begin{verbatim}
S1L8:1640684316-udp-random-
2048-20211229061449.tar.gz
\end{verbatim}
\end{small}

which has been produced by the network we named ``S1L8'', booted when
the time on our local system was 1640684316 seconds after the epoch; this
archive contains the results for the ``udp'' method with ``random''
scheduling and a data size of 2048MB; the run ended on December 29, 2021
at 06:14:49 (local time of the testbed).  The actual timestamp values
are not important per se, but together with the name we assign to the
network they generate unique names for each run (the name has been
folded into multiple lines to fit in the layout of the report, but
of course it is a single string).

If the tar archives are in {\tt\textasciitilde/raw-data}, to extract them to
{\tt\textasciitilde/extracted-data} while renaming files as described:

\begin{small}
\begin{verbatim}
$ extract-data ~/raw-data \
  ~/extracted-data '*'
\end{verbatim}
\end{small}

The last argument is a pattern selecting which files will be extracted.
To extract only some results, use a more specific pattern, for example
{\tt'S1L8:*'} to select only results from a network named ``S1L8''.
(Note that this program requires GNU tar to do the file renaming).

The program produces files with names like:

\begin{small}
\begin{verbatim}
client5.udp.random.2048.
S1L8:1640684316.20211229061449
\end{verbatim}
\end{small}

which contain the same information as the archive name (in a different order),
plus the name of the node which produced a particular file (client5 in this
case).  These files are raw binary data produced by ``lwmon'' so the next
step is to import them into a database.

The ``import-into-sqlite'' script, included in the repository, is a
wrapper around ``lwmon-to-sql'' and ``sqlite'' to import the data into
a database with a suitable schema.  This relies on both lwmon and sqlite
to be installed.

To use this wrapper, simply give it the name of the database and the list of
files to add:

\begin{small}
\begin{verbatim}
import-into-sqlite DB.sqlite \
  ~/extracted-data/*
\end{verbatim}
\end{small}

If the database does not exist, the program creates it automatically
with the following columns:

\begin{small}
\begin{verbatim}
topology    varchar(255)
boot_time   int
host        varchar(255)
experiment  varchar(255)
schedule    varchar(255)
datasize    int
run         int
timestamp   int

name        varchar(255)
parm        varchar(255)
key         varchar(255)
value       int
\end{verbatim}
\end{small}

The first group of columns are determined from the file name (``host''
is the node name, like client5 or router0, and ``topology'' is an
identifier for the network topology, derived from the name given
to the testbed); the second group of columns are the data produced
by ``lwmon''.

\subsection{Analysing results}
{\em The programs described here are in the ``experiment scripts''
repository~\cite{exp:scripts}.}

\TODO{lookup-result, get-summary}

\section{Important notes on repeating this experiment}
\label{configuration}
IPv6 requires multicast, however when preparing to run this experiment
we found that some testbeds did not actually support it.  Some multicast
traffic was forwarded as though it were broadcast, and other traffic
simply dropped. This experiment cannot run under these conditions.

It is very easy to check that multicast packets are forward between nodes:
build ``mcastsend'' and ``mcastread'' from mcast-tools~\cite{mcast-tools},
select two nodes in an experiment which are connected to the same LAN,
and run code like the one shown in figure~\pref{mcast:test}, where the
interface names in the command must be changed to reflect the actual
network interface used on these nodes.
\begin{figure*}[btp]
\begin{verbatim}
node1$ yes 'multicast testing' | \
       mcastsend -i $INTERFACE ff1e::42 4242
node2$ mcastread $INTERFACE ff1e::42 4242 > /tmp/datafile
node2$ (kill mcastread after a few seconds)
node2$ wc /tmp/datafile
 1430130  2860261 25742336 /tmp/datafile
node1$ (kill mcastsend)

node1$ yes 'multicast testing' | \
       mcastsend -i $INTERFACE ff1e::42:1234 4242
node2$ mcastread $INTERFACE ff1e::42:1234 4242 > /tmp/datafile
node2$ (kill mcastread after some time)
node2$ wc /tmp/datafile
 0 0 0 /tmp/datafile
node1$ (kill mcastsend)
\end{verbatim}
\caption{Testing proper switch configuration (also see text)}
\label{mcast:test}
\end{figure*}

The expected result is that both examples show a lot of data stored in
{\tt/tmp/datafile}, as multicast packets are forwarded from the sender
to all nodes which request receiving them.  However on some testbeds we
found that this was not the case, and instead produced the result shown
in the figure: some multicast groups were forwarded, while others were
blocked, and this means that any part of the experiment which uses groups
which are blocked will not be able to proceed. It is best to repeat this
test using a few other multicast groups made up of random numbers to
make sure that they all forward data as expected.  We haven't been able
to determine which kind of switch configuration produces this peculiar
effect so we had to exclude these testbeds from our experiment.

While running the above code, it is also useful to monitor the interface
on both nodes and a third node connected to the same LAN but not running
either ``mcastread'' or ``mcastsend''.  Because of the absence of
listeners on the third node, the expected result is that multicast
packets leave node1, arrive at node2, but are not visible on node3:
this is the effect of MLD snooping on the switch, forwarding packets
only to nodes which require them, and it is the best condition to
run the experiment, as it produces the most useful results.

If the packets arrive at all nodes, the experiment can still proceed,
but the network usage results for the multicast experiment will be less
accurate.  If possible the experiment should be moved to a different
testbed.

In summary, we need to warn anybody wishing to repeat this experiment
to first make sure that the system they are using is configured for
IPv6 multicast, to avoid wasting their time on an experiment which will
produce no results.

\bibliographystyle{plain}
\begin{thebibliography}{99}
\sloppy
\hbadness=6000

\bibitem{lwmon:sources}
  Calvelli, C..
  {\em lwmon: A {\bf\em l}ight-{\bf\em w}eight system {\bf\em mon}itoring tool}.\\
  \url{https://github.com/librestack/lwmon}

\bibitem{exp:scripts}
  Calvelli, C., Payne, E. and B. Sheffield.
  {\em Fed4fire experiment setup scripts}.\\
  \url{https://example.com/TODO-need-url}

\bibitem{unisync:sources}
  Calvelli C. and B. Sheffield.
  {\em Unicast (TCP/UDP) file syncing test program}.\\
  \url{https://github.com/librestack/unisync}

%\bibitem{rfc:2710}
%  Deering, S., Fenner, W. and B. Haberman.
%  {\em Multicast Listener Discovery (MLD) for IPv6}.\\
%  \longurl{https://www.rfc-editor.org/in-notes/rfc2710.txt}%
%  {https://www.rfc-editor.org/}\\
%  \longurl{https://www.rfc-editor.org/in-notes/rfc2710.txt}%
%  {in-notes/rfc2710.txt}

\bibitem{rfc:3170}
  Quinn B. and K. Almeroth.
  {\em IP Multicast Applications: Challenges and Solutions}.
  RFC 3170.\\
  \longurl{https://www.rfc-editor.org/in-notes/rfc3170.txt}%
  {https://www.rfc-editor.org/}\\
  \longurl{https://www.rfc-editor.org/in-notes/rfc3170.txt}%
  {in-notes/rfc3170.txt}

\bibitem{iotupd:paper}
  TODO: iotupd paper

\bibitem{iotupd:sources}
  Sheffield, B.
  {\em Multicast IoT Update Client and Server}.\\
  \url{https://github.com/librestack/iotupd}

\bibitem{jfed}
  {\em jfed 5.9 documentation}.\\
  \longurl{https://doc.ilabt.imec.be/jfed-documentation-5.9/index.html}%
  {https://doc.ilabt.imec.be/}\\
  \longurl{https://doc.ilabt.imec.be/jfed-documentation-5.9/index.html}%
  {jfed-documentation-5.9/index.html}

\bibitem{mcast-tools}
  {\em F0rth/mcast-tools: package containing IPv6-multicast
  routing daemons and tools}.\\
  \url{https://github.com/F0rth/mcast-tools}

\bibitem{pim6sd:sources}
  {\em troglobit/pim6sd: PIM for IPv6 sparse mode daemon.}\\
  \url{https://github.com/troglobit/pim6sd}

\end{thebibliography}
\end{document}


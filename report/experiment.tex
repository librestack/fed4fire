\documentclass[a4paper,11pt,twocolumn]{article}

\usepackage{ifpdf}

\hbadness=3000
\vbadness=4000

\title{Comparing performance of IPv6 multicast and unicast for software updates}
\author{Claudio Calvelli}
\date{Draft 0.6 \today}

\setlength{\unitlength}{0.01\linewidth}
\def\topfaction{0.6}
\def\bottomfraction{0.7}
\setcounter{totalnumber}{5}

\newcommand{\TODO}[1]{\par\noindent%
\hspace*{\fill}%
\framebox{\parbox{0.9\linewidth}{{\bf TODO: }#1}}%
\hspace*{\fill}%
}

% everybody say to just include the hyperref package - it's big, ugly and
% breaks the next command.  This on the other hand works just fine
\ifpdf
\newcommand{\longurl}[2]{%
\pdfstartlink %
attr {/Border [0 0 0]} %
user {/Subtype /Link /A << /S /URI /URI (#1) >>}%
{\footnotesize\tt #2}\pdfendlink}
\newcommand{\url}[1]{\longurl{#1}{#1}}
\else
\newcommand{\url}[1]{{\footnotesize\tt #1}}
\newcommand{\longurl}[2]{{\footnotesize\tt #1}}
\fi

\newcommand{\pref}[1]{%
\ref{#1}%
\ifnum\thepage=0\pageref{#1}\else\ on page~\pageref{#1}\fi%
}

\begin{document}
\maketitle

\begin{abstract}
The librecast project states that ``Multicast is, by definition, the most
efficient way for multiple nodes to communicate''.  This experiment is
designed to provide evidence of this efficiency by comparing multicast
and unicast methods of sending the same data to a large number of nodes,
as would for example happen when a software update is released.

We find that there is partial evidence to support this conclusion,
and use the experience gained here to design furter experiments which
would provide a more definite answer.
\end{abstract}

\section{Introduction}
The first paragraph of RFC 3170~\cite{rfc:3170} states:

\begin{quotation}
\noindent
IP Multicast will play a prominent role on the Internet in the coming
years.  It is a requirement, not an option, if the Internet is going
to scale.  Multicast allows application developers to add more
functionality without significantly impacting the network.
\end{quotation}

There is a need for some experimental data to back these statements.
We concentrate of measuring the impact of {\it software
updates\/} on the network, because the proliferation of connected
devices will make software updates a very important target for
efficient use of the network, and because software updates are
easy to simulate realistically by measuring the impact of copying
a large file to a large number of nodes.

To provide evidence for the above statements, we compare the
following methods of providing updates:

\begin{list}{multicast:}{}
\item[tcp:]
Traditional unicast using a TCP-based service: a
server listens to TCP requests to send a copy of the software
update, and each client requests
the update from the server: this is the mechanism used by the vast
majority of current services.
\item[scp:]
Simple copy of the file using ``scp'' followed by a verification
of the checksum; this is included mostly to confirm that the setup
works correctly with standard, well-tested tools.
\item[multicast:]
Full multicast: a number of servers provide the software
update using multicast, and clients will obtain the updates by
joining a multicast group and waiting for the data to arrive.
\item[udp:]
Unicast using a UDP-based service: this is similar to the
TCP case, but uses datagrams instead of virtual circuits: this
mechanism is introduced because multicast is by necessity based
on datagrams: there is no feedback from receiver to sender, and
we want to help determine which differences may be caused by
unicast vs.\ multicast, and which ones by virtual circuits vs\.
datagrams.
\end{list}

Apart from the ``scp'' runs, do not use encryption in this experiment,
all the three methods send the data unencrypted and verify that it
has arrived correctly using a secure hash: this corresponds to the way
some software updates are distributed, with an HTTP mirror providing
the data and a secure hash provided by some more secure mechanism; we
do not expect the results to be different when excription is used for
all transmissions, as used in many other cases, but we might consider
a future experiment to test this.

Independently of the method selected, there are three ``client''
scheduling strategies:

\begin{list}{immediate:}{}
\item[immediate:]
All clients request updates at approximately the same time.
\item[random:]
Each client will first wait a random time, up to the duration
of the corresponding experiment using the ``immediate'' strategy.
\item[random2:]
Each client will first wait a random time, up to twice the duration
of the corresponding experiment using the ``immediate'' strategy.
\end{list}

We run the simulated software updates in a variety of network
configurations and with a variety of file sizes to simulate the
impact of different types of updates; in each case we measure network
use, server load, client load and speed of update for each combination
of update mechanism and scheduling strategy.

The rest of this report is structured as follows:

Section~\ref{LAN:experiment} describes the simplest possible network
topology in which we can get useful measurements, and provides details
on how we run the experiment.

Sections~\ref{TWOLAN:experiment} and~\ref{GEN:experiment} describe
two more network topologies, incresing the complexity and studying
how different features affect the results.

Section~\ref{results} analyses the result of the experiment and compares
the efficiency of unicast, multicast, and the transitional technology.
There are also notes about testbed issues we identified, because anybody
wishing to repeat the experiment will need to make sure they select
an experiment testbed which is properly configured for IPv6 multicast.

Section~\ref{future} explores the possibility of further experiments,
to make the simulation more realistic and more complete.

Appendix~\ref{programs} provides some more details about the various
programs which ran as part of the experiment, and where to find the
full sources of all these programs.

Appendix~\ref{configuration} provides some important information to
anybody who wants to repeat this experiment, and how to check if
an experiment setup is configured as required.

\section{``LAN'' experiment}
\label{LAN:experiment}

A number of clients (denoted by ${\cal C}$) request software updates
from a single server; the server and all clients share a LAN
so that updates have the shortest possible netowrk path.  This
experiment will allow us to compare multicast and unicast in the
simplest possible setting, and one which is possible on any existing
local network in which IPv6 is enabled, and could represent for example
distributing updates within an organisation.

A second experimental parameters indicates the size of the software updates
as the number ${\cal N}$ of bytes contained in it.  In the real world,
clients may be more or less up-to-date so that each one may request a
subset of all updates available; for this experiment we assume that
all clients have all previous updates and are just requesting the latest
one; a future experiment may consider some more complex ``real life''
scenarios.

Figure~\pref{s1:c8}
\begin{figure}[bp]
\begin{center}
\begin{picture}(90,29)
\put(45,22){\makebox(0,0){\rm\bf S}}
\put(45,16){\line(0,1){3}}
\put(10,16){\line(1,0){70}}
\multiput(10,13)(10,0){8}{\line(0,1){3}}
\multiput(10,10)(10,0){8}{\makebox(0,0){\rm\bf C}}
\end{picture}
\end{center}
\hspace*{\fill}%
\mbox{{\bf S} = server;}%
\hspace*{\fill}%
\mbox{{\bf C} = client}%
\hspace*{\fill}
\caption{Network with8 clients on a single LAN}
\label{s1:c8}
\end{figure}
shows the network topology with ${\cal C} = 8$, i.e.\ there is a
server sending data to 8 clients on a single LAN.

\subsection{Experiment procedure}
For a specified network topology (i.e.\ value for ${\cal C}$), and a list
of update sizes (several distinct values for ${\cal N}$), we implement
that network on an experiment testbed, then run a series of tests on
it using all possible combinations of update size, update method and
scheduling strategy.  For organisational reasons, the testbed actually
has 2 servers, the extra server does not take part in the update but
directs the operations and collects results (we call this extra server
the ``director'').

Each test starts with the director generating a file of the specified size
filled with random data; this is copied to the server (a future experiment
will use multiple servers, so generating the file on the director and
copying it to all servers will make sure all send the same data, and
in preparation for that we have this extra file copy instead of generating
a random file directly on the server).

After generating and copying the file the director waits 60 seconds to
make sure that the 1-minute load average of each node in the system is
down to its baseline value; when we ran experiments without this wait,
we had each run affecting the measurements of the next one, so it did
not produce useful results.

After the 60 seconds wait, the director asks the server node to start:
this means starting two daemons, a resource monitoring tool and the
update provider appropriate for the selected update method.  These
update providers are described below.

After the server has started, the director asks all client nodes to
start as well; for the ``random'' and ``random2'' scheduling strategies
each client will first wait a random time, this step is skipped
for the ``immediate'' strategy; then each client starts a resource
monitoring daemon identical to the one running on the server, and a client
program to obtain the update.

When a client has successfully obtained the update, the monitoring
daemon will record the time it has taken, finish another round of
resource measurements, and sends all the data back to the director.

The director waits for all clients to have sent the data, then asks the
server to stop, which will also trigger a copy of the server's resource
measurements back to the director: all the measurements from all nodes
are collected into a single ``tar'' archive and copied to one of our
servers for later analysis.

The resource monitoring daemon records the following data every second:

\begin{itemize}
\item 1-minute load average as provided by the system
\item user and system CPU time used by the whole system in the last second
\item memory and swap use
\item bytes sent and received on the network interface used to
transfer the update data
\end{itemize}

Additionally, at the end of the experiment it also records the following
data about the update program itself (update provider for server, or
the program obtaining the update for clients):

\begin{itemize}
\item Time elapsed between start and termination of the program, in milliseconds
\item CPU time used by the program itself, in milliseconds
\item CPU time used by the operating system to run the program, in milliseconds
(this includes, for example, time used to obtain data from disk)
\item The termination status: whether the program reported an error
\end{itemize}

The program running to provide the update method will also log some
data via the same mechanism; unicast servers log the time of each
request received and the time the corresponding reply has been
sent completely: this allows a very precise count of the number of
clients ``active'' (i.e. using server's resources) at any time, but
it is not possible for multicast where the server only knows whether
at least one client is active, or they are all inactive. The information
about number of active clients is provided by the client logs in this
case, and is sligtly less accurate.

Since the experiment procedure is automated by running a single program
on the director, where possible we ran it many times on the same
testbed, to have more experimental data without the extra overhead
of setting up a new testbed.

We had several testbeds running this experiment, with a number of
of clients between 20 and 51 depending on available resources at
the time we started each run; these are the results identified
by names like ``S1L20'' or ``S1L51G'' where the number following
the ``L'' is the number of clients. Some of the testbeds only differed
by a minor code change which resulted in no measurable difference,
and the letters added as suffix helped us identify these.  In all
cases, results collected under the same name would have been running
identical code on the same hardware.

As there were never a very large number of free nodes while we ran
the experiment, we will need to leave a detailed study of scale to
a future experiment.

\subsection{Update methods}
The ``multicast'' method uses the ``IoT updater'' demonstration
program~\cite{iotupd:paper} to copy a file from server to clients: on
the server side ``iotupd'' calculates the file's checksum, notifies the
director that it's ready to send data, then runs a loop in which it sends
the whole file and the checksum to a specified multicast group, then
repeats the sending until asked to stop at the end of the experimend.
Each client runs ``iotupc'' which waits for the data to arrive on the
specified group and saves it to a local file, stopping when the file
checksum matches.  The only feedback from client to server is provided by
MLD (Multicast Listener Discovery) messages~cite{rfc:3810}, which allow
the server to know if there is at least one active client, or if they
are all inactive: in particular, there is no mechanism for a client to
request retransmission of missing data: the client just waits for the
server to send it again. More details on the IoT updater can be found
in appendix~\ref{iotupd} or in the source code~\cite{iotupd:sources}.

The unicast ``scp'' method just uses the ``scp'' program (part of
openssh) on each client to connect to the server and ask for a copy of
the file; then it calculates the file digest and compares it with the
digest provided by the director, repeating the whole thing in the
unlikely case there is a mismatch: this allows us to show that the
experiment setup is working with some well-known software; however the
presence of encryption means that the results are not directly comparable
with other experiments; a future experiment in which all methods use
encryption will of course benefit from inclusion of this method.
Instead of using the ``ssh'' daemon already running on each node, we
chose to start another one on a different TCP port, so we can monitor
precisely the server resource usage.

The unicast ``tcp'' experiment is similar in concept to the ``scp''
one, but implemented with code as similar as possible to the multicast
case to make comparisons more meaningful.  On the server side, the
``iotup'' program (in TCP server mode) calculates the file checksum,
notifies the director that it is ready, then waits for connections;
it replies to each connection with the file checksum and the full file
data, sent as a single TCP stream.  On the client side, the ``iotup''
program (in TCP client mode) connects to server, saves the file data,
calculates the checksum and compares it with the one sent by the server;
if the checksum match, the program exits with success, otherwise it
retries the whole download. Because TCP already does its own verification,
it is unlikely that the client will ever have to retry in this experiment
when everything runs in the same building; however in a future larger and
more distributed experiment we can expect to encounter network issues
which will require retries from the client. The ``iotup'' program is
described more fully in appendix~\ref{unisync} and its sources are
available in~\cite{unisync:sources}.

The unicast ``udp'' method is very similar to the ``tcp'' method,
but uses UDP rather than TCP and that implies that retransmissions and
duplicate detection need to be handled at the application level.  On the
server side, the ``iotup'' program (in UDP server mode) calculates the
file checksum, notifies the director that it is ready for clients, then
waits for requests coming in via UDP; these request specify a range of
bytes to send, and the server replies with a sequence of UDP packets,
each of which contain the same information as the packets sent using the
``multicast'' method.  Each client starts by requesting the whole file
(specifying both start and end offsets as 0, which the server interprets
as ``from 0 to end of file'') and waiting for data: if there is no reply
within a pre-determined time, it will retry the request.  Once at least
one packet arrives to the client, it will know the total data size and the
file checksum, and will have part of the data.  The client will wait until
all the expected data has arrived, or a timeout occurs in which no new
packets have arrived for a pre-defined time.  The client will then decide
whether any part of the file needs retransmitting and continue until
it has received all the data it expects, and the file checksum matches.
The ``iotup'' program is described more fully in appendix~\ref{unisync}
and its sources are available in~\cite{unisync:sources}.

\section{``Two LANs'' experiment}
\label{TWOLAN:experiment}

Similar to the previous experiment, but we investigate the effect of a
multicast router in the network: there are two LANs connected together
by a single router; the server is on the first LAN, and all the clients
are on the second LAN.  Like the previous experiments, the parameters are
the number of clients ${\cal C}$, and the update size in bytes ${\cal N}$.

Figure~\pref{s1:r1:c8}
\begin{figure}[btp]
\begin{center}
\begin{picture}(90,38)
\put(45,31){\makebox(0,0){\rm\bf S}}
\put(45,25){\line(0,1){3}}
\put(45,22){\makebox(0,0){\rm\bf R}}
\put(45,16){\line(0,1){3}}
\put(10,16){\line(1,0){70}}
\multiput(10,13)(10,0){8}{\line(0,1){3}}
\multiput(10,10)(10,0){8}{\makebox(0,0){\rm\bf C}}
\end{picture}
\end{center}
\hspace*{\fill}%
\mbox{{\bf S} = server;}%
\hspace*{\fill}%
\mbox{{\bf R} = router;}%
\hspace*{\fill}%
\mbox{{\bf C} = client}%
\hspace*{\fill}
\caption{Two LANs network with 8 clients}
\label{s1:r1:c8}
\end{figure}
shows the network topology with ${\cal C} = 8$, i.e.\ the same setting
as the previous example (figure~\pref{s1:c8}) but with the clients
separated from the server by a single router.

The experimental procedure is very similar to the previous experiment,
we only describe the differences between them here.

After copying the update data to the server and waiting 60 seconds, the
director will ask the router to start its own resource monitoring, and,
for the multicast experiment, to start a multicast routing daemon. We
used ``lcroute''~\cite{lcroute:sources}, which will form part of our
own multicast routing platform. The director then waits for the router
to signal that it has started and is ready to go.

After that, the experiment proceeds identically with the director starting
the server and all clients and waiting for results.  There is an extra step
at the end: after the server has stopped, the director will ask the router
to stop too, and waits for confirmation of this.

We only ran a 20 clients version of this experiment, when there happened
to be free resources for this but not for anything larger. However we also
had a time when one of the clients just failed to boot, so we ran it as
a 19 clients experiment.  Using a similar name scheme to the single LAN
experiment, the results are identified as ``S1R1L19C'', ``S1R1L19D''
and ``S1R1L20A'' (the ``R1'' means that there was a single router in
the network).

\section{``Generic'' experiment}
\label{GEN:experiment}

An extension of the previous (``Two LANs'') experiment includes a longer
network path between clients and server; for simplicity, and to generate
the networks automatically, we specify a number of clients per LAN
(denoted by ${\cal L}$) and the length of the network path indicated by
the number of routers in the path, ${\cal R}$. The total number of clients
will be ${\cal C} = {\cal L} * 2^{{\cal R} - 1}$, and the routers form a
tree structure.

A couple of examples will make this clearer: figure~\pref{s1:r3:l2}
\begin{figure}[bp]
\begin{center}
\begin{picture}(90,62)
\put(45,55){\makebox(0,0){\rm\bf S}}
\put(45,49){\line(0,1){3}}
\put(45,46){\makebox(0,0){\rm\bf R}}
\put(45,40){\line(0,1){3}}
\put(25,40){\line(1,0){40}}
\multiput(25,37)(40,0){2}{\line(0,1){3}}
\multiput(25,34)(40,0){2}{\makebox(0,0){\rm\bf R}}
\multiput(25,28)(40,0){2}{\line(0,1){3}}
\multiput(15,28)(40,0){2}{\line(1,0){20}}
\multiput(15,25)(20,0){4}{\line(0,1){3}}
\multiput(15,22)(20,0){4}{\makebox(0,0){\rm\bf R}}
\multiput(15,16)(20,0){4}{\line(0,1){3}}
\multiput(10,16)(20,0){4}{\line(1,0){10}}
\multiput(10,13)(10,0){8}{\line(0,1){3}}
\multiput(10,10)(10,0){8}{\makebox(0,0){\rm\bf C}}
\end{picture}
\end{center}
\hspace*{\fill}%
\mbox{{\bf S} = server;}%
\hspace*{\fill}%
\mbox{{\bf R} = router;}%
\hspace*{\fill}%
\mbox{{\bf C} = client}%
\hspace*{\fill}
\caption{Network with 8 clients, 2 clients per LAN}
\label{s1:r3:l2}
\end{figure}
shows the network topology with ${\cal R} = 3$ and ${\cal L} = 2$,
so that the 8 clients are organised in 4 separate LANs, with
7 routers forming a tree structure with the server connected to
the root of the tree. For comparison, figure~\pref{s1:r2:l4}
\begin{figure}[bpt]
\begin{center}
\begin{picture}(90,50)
\put(45,43){\makebox(0,0){\rm\bf S}}
\put(45,37){\line(0,1){3}}
\put(45,34){\makebox(0,0){\rm\bf R}}
\put(45,28){\line(0,1){3}}
\put(25,28){\line(1,0){40}}
\multiput(25,25)(40,0){2}{\line(0,1){3}}
\multiput(25,22)(40,0){2}{\makebox(0,0){\rm\bf R}}
\multiput(25,16)(40,0){2}{\line(0,1){3}}
\multiput(10,16)(40,0){2}{\line(1,0){30}}
\multiput(10,13)(10,0){8}{\line(0,1){3}}
\multiput(10,10)(10,0){8}{\makebox(0,0){\rm\bf C}}
\end{picture}
\end{center}
\hspace*{\fill}%
\mbox{{\bf S} = server;}%
\hspace*{\fill}%
\mbox{{\bf R} = router;}%
\hspace*{\fill}%
\mbox{{\bf C} = client}%
\hspace*{\fill}
\caption{Network with 8 clients, 4 client per LAN}
\label{s1:r2:l4}
\end{figure}
shows the same number of clients arranged on 2 separate LANs
(${\cal L} = 4$) so that there are only 2 routers between each
client and the server (${\cal R} = 2$).

This is still a simplified view of a real system, but allows to
extend the previous experiments to different circumstances.  A
future experiment might consider different networks.

The experiment proceeds almost identically to the ``Two LANs''
experiment described above: there are more routers, but they are
all set up in the same way as the single router on that experiment.

We ran experiments corresponding to both examples shown in the figures,
using 20 clients rather than 8.  We also ran a 40 clients version of the
``3 router levels, 4 client LANs'' experiment.  Since there are 3 levels
of routers, we called these experiments ``S1R3L5B'', ``S1R3L5C'' and
``S1R3L10H'' (the ``L'' indicates the number of clients per LAN, so
in this case the total number of clients in the network is four times
the number following the ``L'').

\section{Experiment results}
\label{results}

All the raw data produced by this experiment, as well as all the processed
data referred to in this section is available~\cite{data}.  In this section
we show some results we can draw from the data.  The appendices and software
they cite describe how to convert the data to other formats, and how we
processed it.

\subsection{Run time}
The first result we consider is the total time taken by each client
to obtain the software update, showing separate averages for each network
we ran and for each data size; also showing averages over all networks
with the same number of clients, and over all experiments.

Table~\pref{runtime:20:single} and the following tables show three
representative set of results for single LAN experiments with 20,
40 and 50 clients respectively.
\begin{table*}[p]
\vskip -6ex
\begin{small}
\begin{center}
\input run-time-20-single
\end{center}
\end{small}
\caption{Run time averaged on all 20-clients single LAN experiments}
\label{runtime:20:single}
\end{table*}
\begin{table*}[p]
\vskip -6ex
\begin{small}
\begin{center}
\input run-time-40-single
\end{center}
\end{small}
\caption{Run time averaged on all 40-clients single LAN experiments}
\label{runtime:40:single}
\end{table*}
\begin{table*}[p]
\vskip -6ex
\begin{small}
\begin{center}
\input run-time-50-single
\end{center}
\end{small}
\caption{Run time averaged on all 50-clients single LAN experiments}
\label{runtime:50:single}
\end{table*}
Because of the way the number of clients has an effect on (unicast)
servers, we do not average over all experiments, but only over experiments
with the same number of clients. The complete set of tables for all
the experiment sizes we have ran are available in the online data~\cite{data},
and the appendix describes how to generate these and other tables
from the raw data, also available online.

\TODO{Show graphs}

We use this data to consider the effect of scheduling on all update
methods: multicast is largely unaffected, an update takes about the
same time no matter when it's requested; on the other hand, all unicast
method show quite a difference due to scheduling, with ``immediate''
being extremely slow, ``random2'' considerably faster, and ``random''
intermediate between the two. The conclusion we can draw is that having
everything happening at once is bad for unicast, while multicast doesn't
even notice the difference.  We interpret this by remembering that unicast
needs to send a separate data stream to each client, with overlapping
requests competing for the available network bandwidth, while multicast
sends a single stream; random scheduling reduces the overlap between
clients compared to immediate, and so results in the client requiring
less time to obtain the update, and random2 reduces the overlap even
more with the corresponding result in terms of speed.  We will return
to this point later when analysing server resource usage.

Extrapolating from this (and hoping to confirm this with a future much
larger future experiment), multicast would remain largely unaffected
by adding more clients, while unicast would show an even more
pronounced effect.  In particular, the strategy of randomising
updates to avoid overloading a server only works up to a limit:
when it becomes impossible to schedule updates to avoid overlap,
the only solution would then be to add servers, with the obvious
environmental and economical costs; multicast on the other hand
would continue to be considerate on resources, with any scheduling
strategy.

Moving to a different network topology, tables~\pref{runtime:20:lans}
and~\pref{runtime:40:lans} show the same data collected from experiments
with 3 levels of routers and with 20 and 40 nodes respectively
(arranged as 5 and 10 clients per LAN, with 4 client LANs).
\begin{table*}[p]
\vskip -6ex
\begin{small}
\begin{center}
\input run-time-20-lans
\end{center}
\end{small}
\caption{Run time averaged on all 20-clients multi-LAN experiments}
\label{runtime:20:lans}
\end{table*}
\begin{table*}[p]
\vskip -6ex
\begin{small}
\begin{center}
\input run-time-40-lans
\end{center}
\end{small}
\caption{Run time averaged on all 40-clients multi-LAN experiments}
\label{runtime:40:lans}
\end{table*}

\TODO{Show graphs}

These tables show a different story, with multicast seeming to have became
slower compared to the single LAN case, and in fact random scheduling is
now visibly worse than immediate; while unicast seems to be unaffected
by the presence of routers.  However, the overall effect of scheduling
on multicast is still less than on unicast.

There are two sources for the extra time taken by the multicast update.
MLDv2 works on a LAN, so the routers need to forward this information
before the servers know they need to start sending. And once the multicast
data starts flowing, the kernel will need to query a routing daemon
to know what to do with it. Since this extra delay is introduced
when a client starts up, it is more visible with random scheduling:
with immediate, whichever client happens to be fastest at starting up
will see the delay while the rest don't need to.  We will return to the
issue of routing later when looking at router resource usage.

Extrapolating again from the data, we expect that increasing the number
of clients will show that unicast continues to become slower when requests
overlap, while multicast might show the opposite effect: as more and more
clients send requests, there will be more overlap even in the case of random
scheduling, and this would reduce the overall delay introduced by routing.
A future experiment will need to look into this.

\subsection{Server resources}

Table~\pref{server:multicast} shows the data sent by the server and
the load level for each number of active clients during the multicast
update experiment. The data is averaged over all experiments which used
multicast update, file size 2GB and schedule immediate. The network
data is measured in megabytes sent per second, and the load data is the
fraction of CPU used.
\begin{table*}[p]
\vskip -18ex
\begin{small}
\begin{center}
\input server-multicast
\end{center}
\end{small}
\caption{Server resource data: multicast}
\label{server:multicast}
\end{table*}

By active client we mean a client which is in the middle of obtaining
the file: for the multicast update, this is determined by comparing
the ``client starting to receive'' and ``client received the update''
timestamps in each client's logs with the timestamps of each resource
monitoring data item logged by the server.

We observe how the server load is mostly around 1 or just below,
meaning that the server is using one processor almost constantly,
with the rest being idle. The network data shows that it is sending at
essentially the full bandwidth allowed by a gigabit network (i.e. 125
megabytes per second, or slightly less due to encapsulation overheads).
Only the ``0 clients'' row show lower values.  This corresponds to our
expectation that the multicast server is unaffected by the number of
clients receiving data, with the exception that it can stop sending if
it knows that there are no listeners.

Table~\pref{server:scp} and the two following tables show similar data
for the unicast update mechanism: scp, tcp and udp respectively. In
these tables, the number of active clients is determined using server
timestamps only, as the server logs the time it receives a request and
the time it finishes sending the data.
\begin{table*}[p]
\vskip -18ex
\begin{small}
\begin{center}
\input server-scp
\end{center}
\end{small}
\caption{Server resource data: scp}
\label{server:scp}
\end{table*}
\begin{table*}[p]
\vskip -18ex
\begin{small}
\begin{center}
\input server-tcp
\end{center}
\end{small}
\caption{Server resource data: tcp}
\label{server:tcp}
\end{table*}
\begin{table*}[p]
\vskip -20ex
\begin{small}
\begin{center}
\input server-udp
\end{center}
\end{small}
\caption{Server resource data: udp}
\label{server:udp}
\end{table*}

\TODO{Show graphs}

Note that the udp table has been truncated to fit in the page: the full
table is available with the online data~\cite{data}.  The reason the
table is longer than the others is due to the effect of packet loss
and retransmission requests, where the client could request multiple
retransmissions at once, and these are seen as independent requests by
the server, so appear as multiple active clients. However, from the point
of view of the server it is the number of requests being processed which
determines resource usage, rather than the number of distinct clients
producing these requests, so we decided to leave the data as it is.
Some of the more recent experiments have had the client code modified
to always serialise the retransmission requests, but we did not re-run
all experiments as there appeared to be no reason to do so.

The unicast tables surprised us a bit.  We expected to see the network
constantly saturated as all streams are competing for it, except of course
when there are no active clients, in which case the server would not send
anything.  Instead, it appears that the server isn't always saturating
the network when sending to multiple clients, and that explains how
some testbeds seemed to take even longer than expected to complete the
file copy.  We are not sure how to explain this, unless there is some
hardware bottleneck for example obtaining the data from disk: for
multicast, which reads a file sequentially from start to end in a
single thread, the kernel's readahead may be helping, while the
unicast servers have multiple threads all reading the same file at
different positions, and it may be able to defeat the kernel's
caching.  However we cannot say for sure until we repeat these
experiments measuring other resources such as disk I/O bandwidth.

For server load, scp shows a drop in processor utilisation which appears
to match the drop in network utilisation; however where the network is
fully saturated the load is normally above 1, and growing with the
number of clients: this would reflect the number of processors busy
encrypting data, and we note that the corresponding tcp data shows very
low load, reflecting the fact that all the server is doing is moving
bytes from disk to network card.

Udp server load appears to be very high although it follows a similar
pattern to the scp data. Since there is no encryption and the server
is just moving bytes from disk to network card, this seems to be
a higher processor utilisation than one would expect. It is possible
that the network stack is optimised for TCP and doesn't handle UDP
very well; we have also observed high levels of packet loss at times
which aren't justified by the network setup.  Possibly running these
experiments on different hardware or using a different operating
system may show a different result.  All we can do with these numbers
is show them and offer our guesses.

\subsection{Router resources}

\TODO{Show tables and graphs, and draw conclusions}

\section{Future work}
\label{future}

Due to time limitations we have only measured network performance for
a small set of regular network topologies, corresponding to the example
networks shown in sections~\ref{LAN:experiment} to~\ref{GEN:experiment},
using more clients than shown in the figures; of course the real world
is made up of rather more irregular topologies and it it would be
interesting to investigate more variations in this area in a future set
of experiments.

We also limited the experiments to about 50 clients, as we have been
unable to allocate larger networks: the testbed never had enough free
resources.  To properly test how the various method scale, we would need
some experiment setup where we can easily allocate 500 or more nodes
and have them running for days.

Alternatively, we would like to run the experiment distributed across
several sites to have a much larger number of total nodes, and also a
more representative network structure.  However the unicast experiments
are likely to require massive amount of network bandwidth, and the
multicast experiments require proper multicast configuration at all
sites and multicast routing between then, so these factors will limit
the choice of sites.

We also simplified the software update by assuming that all clients
request exactly the same file, rather than a more complex situation
in which every client requests a different subset of all available
updates, due to its own unique update history; unicast of course
will need very little change: since each client receives its own
separate stream, they don't have to contain the same data; for
multicast, we already have (in the present experiment) servers only
sending data when somebody is listening, so it would never need to
send all possible updates all the time, and we expect multicast
to handle this situation well; however without a corresponding
experiment, ``expect'' is all we can say about this.

All the experiments we ran included a single server.  The main point
of this experiment was to show that a single server is sufficient to
provide updates for a large number of clients using multicast, while
unicast will require multiple servers in this case.  However, there
are reasons other than server and network load why one would want
multiple servers, for example reliability: if the single, extremely
efficient, server has a fault, the updates stop; ideally, these
multiple servers will be reachable by completely different network
paths as well.  We think that multicast will help with that too,
for example multiple servers can each send data at a fraction of the
bandwidth, and when they all work clients will get the advantage of the
combined output from all servers, while a network or server failure
would automatically result in a corresponding reduction of speed, and
the subsequent recovery or replacement of the faulty parts would
automatically result in the system returning to full speed.  This
claim, of course, needs a separate experiment to justify.

Another type of network activity which can benefit from multicast is
live streaming, where the server will only need to send the stream once;
this case is similar to software updates and probably does not need a
separate experiment; however if several choices of bandwidth and quality
are required the situation is different.  In the unicast case it's obvious
how the sender can provide different quality streams to different clients,
for multicast the simplest answer is to provide several streams with
different quality, with the client subscribing to the one which best
match its requirements: this would save network and server resources
but there may be better way of achieving this result, for example using
layered codecs to send only one copy of the lowest quality stream, then
a second stream with the difference between that and the next highest
quality. We don't know at present if these codecs would involve more
server resources than the re-encoding required to provide multiple
stream with different quality, but in any case we would find it useful
to run another experiment to measure these costs and compare them with
the expected savings in terms of network usage.

For this experiment we transmitted all data unencrypted between the nodes
and used a secure hash to determine whether it was received correctly.
This corresponds to a traditional situation in which HTTP mirrors provide
the data, and a checksum is provided over a more secure mechanism for
verification.  More recently, most systems are moving to HTTPS with the
added overhead of encryption on every communication: we expect that the
benefits of multicast shown in this experiment will continue to apply,
but we have not tested this, and will consider a future experiment in
which we extend the multicast update method to add encryption of all
communication, comparing this with the normal stream encryption used
for example with HTTPS.

\appendix
\section{Programs}
\label{programs}

To run each experiment we had to implement a network topology on an
experiment testbed, set up each node in the testbed, run the experiment
itself and collect the results; additionally, we had to analyse the
results of groups of experiments together.  This appendix describes
the programs used for all various tasks, and includes references to
where the full source code can be found for the programs we developed.

\subsection{Preparing a testbed and running an experiment}

{\em The programs described here and other useful tools are in the experiment
setup repository~\cite{exp:scripts} under the {\tt bin} directory for
the programs to run on the local system and the {\tt objects} directory
for the programs to run on the testbed.}

Given the number of servers, clients and routers (if appropriate to the
experiment) we developed a simple program to generate action files
for ``jfed''~\cite{jfed} so that the process could be automated; a single program
``mknet'' provided action files for all the experiment topologies
described in this report by providing appropriate options; for the
networks shown as examples in the figures we just ran:

\begin{small}
\begin{verbatim}
local$ mknet L=8
local$ mknet R=1 L=8
local$ mknet R=3 L=2
local$ mknet R=2 L=4
\end{verbatim}
\end{small}

As can be seen, omitting ``R'' results in a single LAN network in which
the number of clients is specified by ``L'' for consistency with the
other networks (where it indicates the number of clients on each client
LAN).

By default, the program generates an experiment name indicating the
parameters provided: for the four examples above this would be: ``S1L8'',
``S1R1L8'', ``S1R3L2'' and ``S1R2L4''; the data generated will be stored
in a directory inside {\tt/var/tmp} named after the experiment (the name
of the experiment starts with ``S1'' to indicate the number of servers,
in preparation for a future multi-server experiment, and the directory
can be changed with other command-line options).

One of the files generated, {\tt action.yaml}, is suitable for using
as argument to the {\tt-a} (action file) option to the ``jfed-cli''
tool and will provision the testbed; the program also generates {\tt
action.rspec} which is suitable for using with the ``jfed-gui'' tool.
We do not describe these tools here as they are provided by fed4fire,
but see~\cite{jfed}.

Once the testbed is up and running, we need to copy some things to it,
for example the actual programs which will run on it and information about
the experiment to run.  The list of data sizes is also specified at
this point, for example to run with 32, 64 and 512 megabytes on the
first single LAN experiment defined above (``S1L8'')

\begin{small}
\begin{verbatim}
local$ setup-experiment 32,64,512 S1L8
\end{verbatim}
\end{small}

This sets up the ``director'' node and copies the {\tt objects} directory
of the repository to it.  To complete the setup, one needs to connect to
it and then run a program there:

\begin{small}
\begin{verbatim}
local$ ssh-experiment S1L8 director0
director0$ /tmp/experiment/setup-all
\end{verbatim}
\end{small}

The testbed is now ready to run the experiment by running a program on
director0:

\begin{small}
\begin{verbatim}
local$ ssh-experiment S1L8 director0
director0$ cd /tmp/experiment
director0$ ./run-experiment
\end{verbatim}
\end{small}

If required, the ``{\tt run-experiment}'' program can run many times
to obtain more data without additional setup overhead; no need to
repeat any of the previous steps.

Internally, the ``{\tt run-experiment}'' program calls other programs
running on the director, but also on servers, routers and clients
as necessary to implement the procedure described in
sections~\ref{LAN:experiment} to~\ref{GEN:experiment}. These
programs have names like ``{\tt start-tcp-server}'' or
``{\tt start-multicast-router}'' to start what is required for
a particular experiment on a particular node (in this example,
start the TCP experiment on a server, and start the multicast
routing daemon on a router, respectively).  All these programs are
found in the repository cited.

One issue we found while developing programs to automate the experiment
is that network interface names may be different when booting different
testbeds; each node has two interfaces, a control interface used by
the testbed administration, as well as to log in to it from outside
the experiment, and a second interface connected as required by the
experiment's network topology and used to transfer the data files during
the experiment; for a router node, there are obviously more interfaces:
therefore we needed to determine what interface name was actually
assigned to what.  The fed4fire documentation mentions a tool to obtain
the necessary information on each node, however the tool did not work:
it required a version of Python which is no longer available, and all
it produced for us was a syntax error.  Instead of debugging that,
it was easier for us to have the ``setup-all'' script figure out what
interface is going to be used for what based on the MAC address listed
in the output from the jfed program, and configure them as required:
this may be different for each node.  It also sets up the monitoring so
that the interfaces are reported in a consistent way, as is important
when looking at network usage data for routers.

\subsection{Resource monitoring}
\label{lwmon}
{\em The program described here is in the lwmon
repository~\cite{lwmon:sources}.}

There are many monitoring tools for Unix system, however in our experience
they tend to use more resources than programs which do the actual work,
or else they are designed to sample information only once a minute,
which is not enough for this experiment.

Because of experience using other monitoring tools and not finding
one which we actually want to use on a live system, we have developed
our own over the years, which we call ``lwmon'', for Light-Weight
system MONitoring, which, as the name suggests, is very considerate
in its use of resources and can safely run very frequently without
impact on the system.  It can also report on its own resource usage,
so one can confirm that it is, indeed, light-weight.

Without going into complete details, each node sets up its own
configuration for lwmon, which then measures memory, swap, cpu and
network usage and system load every second, its own resource usage every
10 seconds.  The appropriate program (update provider for servers, routing
daemon for routers if requires by the experiment, and the program which
gets the updates for clients) also runs as a child process of lwmon,
so the latter can report on the resource used by this program.

A lwmon configuration for a client is shown in figure~\pref{lwmon:client}.
\begin{figure*}[bp]
\begin{verbatim}
hostname client2

load lavg 1
cpu cpu 1
memory memswap 1
network if1 1 enp6s0
self self 2

program exp 5 /tmp/experiment/start-multicast-client enp6s0
print /tmp/results/client2.multicast.random.64 overwrite binary
\end{verbatim}
\caption{lwmon client configuration}
\label{lwmon:client}
\end{figure*}
This means that load average, memory/swap usage and network usage are
sampled every second, lwmon's own resource usage every 2 seconds, will
run the appropriate program for a particular experiment (in this case,
update via multicast), and save the information into a file in a compact
binary format. The second column of the lines specifying what to measure
is the name used to report it.

The program running does not depend on the scheduling strategy selected,
as that is handled before: we do not want to measure the time it takes
to sleep for a random duration, only the time it takes to download the
update.  The file name for the results, on the other hand, contain the
scheduling strategy (in this case, random) and the update size (64
megabytes), as we need to keep things distinct.

Another thing to note is that the ``network'' line asks to monitor
the interface using its systemd name (enp6s0 in this example) because
that's how it will be able to find it in the system, but reports it
using the name ``if1'' as this is the interface name we have used
in the action file and rspec.

The configuration for a server is essentially identical, with ``client''
replaced by ``server'', and for a router it is very similar, as shown
in figure~\pref{lwmon:router}.
\begin{figure*}[bp]
\begin{verbatim}
hostname router0

load lavg 1
cpu cpu 1
memory memswap 1
network if1 1 enp4s0
network if2 1 enp6s0
self self 2

program exp 5 /tmp/experiment/start-multicast-router enp4s0
print /tmp/results/router0.multicast.random.64 overwrite binary
\end{verbatim}
\caption{lwmon router configuration}
\label{lwmon:router}
\end{figure*}
The network interface reported as ``if1'' has network traffic going
to or from clients, and ``if2'' has traffic going to or from servers.

Once the ``{\tt start-}\ldots'' program terminates, lwmon automatically
reports on its resource usage and the wall clock time it has taken to run,
then runs one more round of measurements and exits.  For clients, the
program normally terminates when it has obtained the update successfully;
for servers and routers the program terminates when the director signals
the end of the experiment.

The program which generates the lwmon configuration file and calls lwmon
will wait for it to terminate, then copies the file it produced back
to the director node. This allows the director to collect all the
data about the experiment in one place.

As mentioned, lwmon produces a file containing data in a packed binary
format. To just look at the data, the tool has an option to read that
binary file back in and produce a human-readable output:

\begin{small}
\begin{verbatim}
$ lwmon -P - \
  -R data/router0.multicast.random.64
\end{verbatim}
\end{small}

There is a separate tool which reads one or more data files and produces
SQL statements which can be used to import it into a database, for example:

\begin{small}
\begin{verbatim}
$ lwmon-to-sql [options] FILES | \
  sqlite3 database.sqlite
\end{verbatim}
\end{small}

As described below in~\ref{summaries}, for this experiment we have developed
a tool which calls {\tt lwmon-to-sql} in the appropriate way to import
experiment results in a format suitable for further analysis.

\subsection{Multicast update method}
\label{iotupd}
\TODO{iotupd}

\subsection{Unicast update methods}
\label{unisync}
\TODO{unisync}

\subsection{Summarising data}
\label{summaries}

{\em The programs described here are in the ``experiment scripts''
repository~\cite{exp:scripts}.}

The ``lwmon'' program (appendix~\ref{lwmon}) produces a lot of data, as it
measures several items every second, and of course each node in the
experiment produces its own set of measurements.  The end result is that
we have tens of millions of data items divided into thousands of ``tar''
archives, each one produced by a single experiment run; inside these
archives, files are named after the node which produced them (for example,
client1 or router0) and the actual experiment ran (for example, multicast
or tcp) but other information is only in the name of the archive itself,
so the first step is to extract all these files renaming them so that
the names contain all the necessary information (this situation is because
when we started running the experiments, only the ``director'' node
had all the information, but the file names were generated by the nodes
creating the files: in a future experiment we are planning to change this).

These tar archives have names like:

\begin{small}
\begin{verbatim}
S1L20C-vwall1-20220119101508-multicast-
random-2048-20220131154314.tar.gz
\end{verbatim}
\end{small}

\noindent
this example has been produced by the network we named ``S1L20C'', booted
on virtual wall 1 when the time on our local system was 19/Jan/2022
at 10:15:08; this archive contains the results for the ``multicast''
method with ``random'' scheduling and a data size of 2048MB; the run
ended on 31/Jan/2022 at 15:43:14 (local time of the testbed).  The actual
timestamp values are not important per se, but together with the name we
assign to the network they generate unique names for each run (the name
has been folded into multiple lines to fit in the layout of the report,
but of course it is a single string).

The {\tt averages} script reads the lwmon data directly and produces
summaries as described below; however this can be slow so it uses a
database to cache intermediate results.  This database could also
be useful for other processing. There is a table indexing tarballs
and two other tables for different types of cached summaries.

The table indexing tarballs, ``tarballs'' has the following columns:

\begin{small}
\begin{verbatim}
id             int
filename       varchar(256)
filesize       int
mtime          int

topology       varchar(256)
suffix         varchar(32)
testbed        varchar(32)
boot_time      int
update_method  varchar(256)
schedule       varchar(256)
file_size      int
run_time       int
n_servers      int
router_levels  int
n_clients      int
\end{verbatim}
\end{small}

The first group of columns are the file information: ``id'' is the
internal unique identifier used in the cache database, ``filename''
is the tarball's filename, and ``filesize'' and ``mtime'' are provided
by the filesystem and are used by the program to update the cached data
if the file appears to have changed (this can happen if we run the
program while results are still arriving from the testbed).

The second group of columns are obtained by splitting the file name
into its components, and interpreting the testbed name to determine
the number of clients and routers.

The decoded lwmon data for a particular element is accumulated in the
``data'' table which contains the following columns:

\begin{small}
\begin{verbatim}
tar_id         int
dataname       varchar(256)
count          int
min            float
max            float
total          float
square         float
\end{verbatim}
\end{small}

Each data item can be present multiple times in the same tarball
(for example, each client could contribute one element); these are
all added together in the ``total'' column, and their squares are
added in the ``square'' column; when selecting a tarball for
processing, we can use this information to calculate averages and
standard deviations.

Another table, ``summary'', contain information grouped by number of
active; it has one extra column, ``n{\textunderscore}clients''.

The ``averages'' script produces averages from a specified subset of
experiment runs, and also maintains the cache database.  The general
usage is:

\begin{small}
\begin{verbatim}
$ averages [options] DATA_NAME \
  CACHE_DATABASE \
  TARBALL [TARBALL]... | less
\end{verbatim}
\end{small}

This will probably produce a lot of data, so it's best to send the output
to a file or pipe into a pager.

Currently, ``DATA{\textunderscore}NAME'' can be one of ``run-time'',
``server-tx'' and ``server-load'' described below, and a sample output
is shown in figures~\ref{result:example1} and~\pref{result:example2}.
\begin{figure*}[p]
\begin{small}
\begin{verbatim}
$ ./bin/averages -p run-time ~/DB/summary.sqlite ~/results/S1L49F-
UPDATE    SCHEDULE  SIZE          AVG #DATA          MIN          MAX      STD
multicast random      32        0.502   539        0.403        0.767    0.069
multicast random2     32        0.507   539        0.406        0.793    0.077
multicast immediate   32        0.512   539        0.406        0.795    0.083
tcp       random2     32        0.516   539        0.372        1.182    0.186
tcp       random      32        0.733   539        0.372        1.970    0.381
scp       random2     32        0.885   539        0.735        1.858    0.138
scp       random      32        0.974   539        0.742        2.129    0.207
...
scp       immediate 2048    15:01.874   539    14:01.121    15:31.685   12.585
udp       immediate 2048    15:30.195   539    14:32.472    15:48.049   15.527
\end{verbatim}
\end{small}
\caption{Example experiment result}
\label{result:example1}
\end{figure*}
\begin{figure*}[p]
\begin{small}
\begin{verbatim}
$ ./bin/averages -p server-tx ~/DB/summary.sqlite ~/results/S1L49F-
UPDATE    SCHEDULE  SIZE #CLIENT        AVG #DATA        MIN        MAX    STD
scp       immediate  128      24        0.0     1        0.0        0.0      -
tcp       immediate  128      10        0.0     1        0.0        0.0      -
tcp       immediate  512      21        0.0     1        0.0        0.0      -
tcp       immediate  512      31        0.0     1        0.0        0.0      -
multicast immediate   32       2        0.0     2        0.0        0.0    0.0
multicast immediate  128       7        0.0     2        0.0        0.0    0.0
...
udp       immediate  512      23      180.3     2      120.1      240.6   85.2
udp       immediate   32      41      180.3     2      120.1      240.6   85.2
tcp       immediate 2048      41      180.6     4      120.3      240.8   69.5
\end{verbatim}
\end{small}
\caption{Example experiment result}
\label{result:example2}
\end{figure*}
The program determines the number of active clients by combining information
about client start and stop times and adds that to the table.

We have currently defined three data types, but the script allows adding more
very easily:

\begin{list}{server-load:}{}
\item[run-time:]
Total time the client required from sending the first request to server
until it received the complete file.
\item[server-load:]
Server load by number of active clients; this is sampled every second
or more often if there is a change in the number of active clients,
and is the total number of CPU millisecond reported used divided by
the milliseconds since the previous sample.
\item[server-tx:]
Data sent over the network per second; this number is sampled every
second or more often if there is a change in the number of active
clients, and is the number of bytes sent divided by the number of
milliseconds since the previous sample, and further divided to
obtain a number of megabytes per second.
\end{list}

A pre-filled cache database is available online together with the raw
data~\cite{data}

\section{Important notes on repeating this experiment}
\label{configuration}
IPv6 requires multicast, however when preparing to run this experiment
we found that some testbeds did not actually support it.

It is very easy to check that multicast packets are forwarded between nodes:
build ``mcastsend'' and ``mcastread'' from mcast-tools~\cite{mcast-tools},
select two nodes in an experiment which are connected to the same LAN,
and run code like the one shown in figure~\pref{mcast:test}, where the
interface names in the command must be changed to reflect the actual
network interface used on these nodes.
\begin{figure*}[tbp]
\begin{verbatim}
node1$ yes 'multicast testing' | \
       mcastsend -i $INTERFACE ff1e::42 4242
node2$ mcastread $INTERFACE ff1e::42 4242 > /tmp/datafile
node2$ (kill mcastread after a few seconds)
node2$ wc /tmp/datafile
 1430130  2860261 25742336 /tmp/datafile
node1$ (kill mcastsend)

node1$ yes 'multicast testing' | \
       mcastsend -i $INTERFACE ff1e::42:1234 4242
node2$ mcastread $INTERFACE ff1e::42:1234 4242 > /tmp/datafile
node2$ (kill mcastread after some time)
node2$ wc /tmp/datafile
 0 0 0 /tmp/datafile
node1$ (kill mcastsend)
\end{verbatim}
\caption{Testing proper switch configuration (also see text)}
\label{mcast:test}
\end{figure*}

The expected result is that both examples show a lot of data stored in
{\tt/tmp/datafile}, as multicast packets are forwarded from the sender
to all nodes which request receiving them.  However on some testbeds we
found that this was not the case, and instead produced the result shown
in the figure: some multicast groups were forwarded, while others were
blocked, and this means that any part of the experiment which uses groups
which are blocked will not be able to proceed. It is best to repeat this
test using a few other multicast groups made up of random numbers to
make sure that they all forward data as expected.  We haven't been able
to determine which kind of switch configuration produces this peculiar
effect so we had to exclude these testbeds from our experiment.

While running the above code, it is also useful to monitor the interface
on both nodes and a third node connected to the same LAN but not running
either ``mcastread'' or ``mcastsend''.  Because of the absence of
listeners on the third node, the expected result is that multicast
packets leave node1, arrive at node2, but are not visible on node3:
this is the effect of MLD snooping on the switch, forwarding packets
only to nodes which require them, and it is the best condition to
run the experiment, as it produces the most useful results.

If the packets arrive at all nodes, the experiment can still proceed,
but the network usage results for the multicast experiment will be less
accurate.  If possible the experiment should be moved to a different
testbed.

In summary, we need to warn anybody wishing to repeat this experiment
to first make sure that the system they are using is configured for
IPv6 multicast, to avoid wasting their time on an experiment which will
produce no results.

\bibliographystyle{plain}
\begin{thebibliography}{99}
\sloppy
\hbadness=6000

\bibitem{data}
  TODO: all the available data

\bibitem{lwmon:sources}
  Calvelli, C..
  {\em lwmon: A {\bf\em l}ight-{\bf\em w}eight system {\bf\em mon}itoring tool}.\\
  \url{https://github.com/librestack/lwmon}

\bibitem{lcroute:sources}
  TODO: lcroute sources

\bibitem{exp:scripts}
  Calvelli, C., Payne, E. and B. Sheffield.
  {\em Fed4fire experiment setup scripts}.\\
  \url{https://example.com/TODO-need-url}

\bibitem{unisync:sources}
  Calvelli C. and B. Sheffield.
  {\em Unicast (TCP/UDP) file syncing test program}.\\
  \url{https://github.com/librestack/unisync}

%\bibitem{rfc:2710}
%  Deering, S., Fenner, W. and B. Haberman.
%  {\em Multicast Listener Discovery (MLD) for IPv6}.\\
%  \longurl{https://www.rfc-editor.org/in-notes/rfc2710.txt}%
%  {https://www.rfc-editor.org/}\\
%  \longurl{https://www.rfc-editor.org/in-notes/rfc2710.txt}%
%  {in-notes/rfc2710.txt}

\bibitem{rfc:3170}
  Quinn B. and K. Almeroth.
  {\em IP Multicast Applications: Challenges and Solutions}.
  RFC 3170.\\
  \longurl{https://www.rfc-editor.org/in-notes/rfc3170.txt}%
  {https://www.rfc-editor.org/}\\
  \longurl{https://www.rfc-editor.org/in-notes/rfc3170.txt}%
  {in-notes/rfc3170.txt}

\bibitem{rfc:3810}
  Vida, R. and L. Costa, eds.
  {\em Multicast Listener Discovery Version 2 (MLDv2) for IPv6}.
  RFC 3810.\\
  \longurl{https://www.rfc-editor.org/in-notes/rfc3810.txt}%
  {https://www.rfc-editor.org/}\\
  \longurl{https://www.rfc-editor.org/in-notes/rfc3810.txt}%
  {in-notes/rfc3810.txt}

\bibitem{iotupd:paper}
  TODO: iotupd paper

\bibitem{iotupd:sources}
  Sheffield, B.
  {\em Multicast IoT Update Client and Server}.\\
  \url{https://github.com/librestack/iotupd}

\bibitem{jfed}
  {\em jfed 5.9 documentation}.\\
  \longurl{https://doc.ilabt.imec.be/jfed-documentation-5.9/index.html}%
  {https://doc.ilabt.imec.be/}\\
  \longurl{https://doc.ilabt.imec.be/jfed-documentation-5.9/index.html}%
  {jfed-documentation-5.9/index.html}

\bibitem{mcast-tools}
  {\em F0rth/mcast-tools: package containing IPv6-multicast
  routing daemons and tools}.\\
  \url{https://github.com/F0rth/mcast-tools}

\end{thebibliography}
\end{document}

